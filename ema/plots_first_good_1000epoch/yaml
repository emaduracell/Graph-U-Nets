# Model hyperparameters
model:
  activation_gnn: "ELU"
  activation_mlps_final: "ELU"
  hid_gnn_layer_dim: 128
  hid_mlp_dim: 256
  k_pool_ratios: [0.9, 0.8, 0.7]
  dropout_gnn: 0 # 0.1
  dropout_mlps_final: 0 # 0.1

# Training parameters
training:
  lr: 0.01 # default = 1e-4
  epochs: 1000
  batch_size: 4
  shuffle: False
  adam_weight_decay: 1e-4
  num_train_trajs: 1
  mode: "overfit"
  gamma_lr_scheduler: 0.9995 # lr_final = lr0 * gamma^epochs

